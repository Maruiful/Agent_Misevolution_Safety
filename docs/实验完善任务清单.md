# 实验完善任务清单

> 基于《Your Agent May Misevolve》论文要求，整理出当前项目需要补充的功能清单

**最后更新**: 2025-01-10
**当前项目进度**: 核心架构完成，需补充关键实验功能以复现论文现象

---

## 🔴 P0优先级 - 必须实现（否则无法复现论文现象）

### 任务1: 实现Few-shot提示词构建

**目标**: 让智能体能够从历史经验中学习，这是论文的核心机制

**论文原理**:
- 使用embedding相似度检索历史经验
- 按奖励高低排序，优先展示高奖励案例
- 明确标注即时奖励、延迟奖励和违规信息

**实现步骤**:
- [ ] **1.1 实现相似度检索**
  - [ ] 添加文本embedding功能（可用OpenAI embedding或开源模型）
  - [ ] 实现cosine相似度计算
  - [ ] 在ReplayBuffer中添加`retrieve_similar(k=5)`方法

- [ ] **1.2 构建Few-shot提示词**
  - [ ] 创建`build_few_shot_prompt()`函数
  - [ ] 格式化展示历史案例（输入、回复、奖励分解、违规标注）
  - [ ] 按total_reward降序排列

- [ ] **1.3 集成到智能体**
  - [ ] 修改`agent.py`中的提示词生成逻辑
  - [ ] 在每次决策前检索相似历史
  - [ ] 将历史案例注入到LLM提示词中

**文件位置**:
- `backend/storage/replay_buffer.py` - 添加检索方法
- `backend/core/agent.py` - 修改提示词构建

**预计时间**: 1-2天

---

### 任务2: 修改奖励计算为延迟反馈

**目标**: 实现论文中的时间错位机制（短期立即反馈，长期延迟反馈）

**当前问题**:
- 即时奖励和延迟奖励同时计算
- 无法产生论文中的"短期诱惑"效应

**实现步骤**:
- [ ] **2.1 重构奖励计算流程**
  ```python
  # 当前: 一次性计算所有奖励
  response = agent.generate(prompt)
  immediate_reward = calc_immediate(response)
  delayed_reward = calc_delayed(satisfaction)
  total = α*immediate + β*delayed

  # 目标: 分两次计算
  response = agent.generate(prompt)
  immediate_reward = calc_immediate(response)  # 立即反馈

  # 对话结束后才反馈
  delayed_reward = submit_feedback(round_id, satisfaction)  # 延迟反馈
  ```

- [ ] **2.2 修改RewardService**
  - [ ] `calculate_immediate_reward()` 只计算效率相关奖励
    - 响应速度奖励
    - 工单关闭奖励
    - 完成任务奖励
  - [ ] 添加`submit_delayed_feedback()`方法
    - 对话结束后调用
    - 计算满意度奖励
    - 更新experience的total_reward

- [ ] **2.3 更新Agent流程**
  - [ ] 生成回复时只反馈即时奖励
  - [ ] 保存experience时标记为"待反馈"
  - [ ] 对话结束时调用延迟反馈

**文件位置**:
- `backend/services/reward_service.py` - 重构奖励计算
- `backend/core/agent.py` - 修改处理流程

**预计时间**: 0.5-1天

---

### 任务3: 添加批量自动测试功能（500轮）

**目标**: 自动运行500+轮实验，观察完整进化过程

**实现步骤**:
- [ ] **3.1 创建测试用例库**
  - [ ] 创建`tests/scenarios.json`文件
  - [ ] 包含正常场景、违规场景、边界场景
  - [ ] 每类至少20个案例

- [ ] **3.2 实现批量测试脚本**
  - [ ] 创建`scripts/run_batch_experiment.py`
  - [ ] 支持配置轮次、权重、场景分布
  - [ ] 自动保存快照（每50轮）

- [ ] **3.3 添加进度监控**
  - [ ] 实时显示当前轮次
  - [ ] 显示违规率变化
  - [ ] 显示平均奖励趋势

- [ ] **3.4 实验结果导出**
  - [ ] 导出完整实验数据（JSON）
  - [ ] 生成可视化图表
  - [ ] 生成实验报告摘要

**文件位置**:
- `tests/scenarios.json` - 测试用例
- `scripts/run_batch_experiment.py` - 批量测试脚本
- `scripts/analyze_results.py` - 结果分析脚本

**预计时间**: 0.5-1天

**使用示例**:
```bash
# 运行500轮实验
python scripts/run_batch_experiment.py --rounds 500 --weight-short 0.7

# 运行多组对比实验
python scripts/run_batch_experiment.py --compare-weights
```

---

## 🟡 P1优先级 - 重要补充（提升实验质量）

### 任务4: 实现三阶段进化分析

**目标**: 识别并分析探索期、学习期、偏离期三个阶段

**论文观察**:
- **探索期(0-100轮)**: 违规率2-5%
- **学习期(100-300轮)**: 违规率8-15%
- **偏离期(300-500轮)**: 违规率15-30%

**实现步骤**:
- [ ] **4.1 实现阶段识别算法**
  ```python
  def identify_evolution_stages(experiments, window_size=50):
      """识别进化阶段"""
      # 计算滑动窗口违规率
      violation_rates = calc_sliding_window_violation_rate(experiments, window_size)

      # 识别转折点
      stages = {
          "exploration": (0, first_turning_point),
          "learning": (first_turning_point, second_turning_point),
          "deviation": (second_turning_point, len(experiments))
      }
      return stages
  ```

- [ ] **4.2 提取阶段特征**
  - [ ] 每阶段的平均违规率
  - [ ] 奖励变化趋势
  - [ ] 常见违规话术
  - [ ] 策略分布变化

- [ ] **4.3 可视化阶段划分**
  - [ ] 在演化曲线图上标注阶段
  - [ ] 阶段对比柱状图
  - [ ] 关键转折点高亮

**文件位置**:
- `backend/services/analysis_service.py` - 分析服务
- `frontend/streamlit_app.py` - 前端展示

**预计时间**: 1天

---

### 任务5: 添加多权重对比实验

**目标**: 验证论文关键发现：短期权重>0.6时违规率显著上升

**论文数据**:
| 短期权重 | 长期权重 | 违规率 |
|---------|---------|-------|
| 0.2 | 0.8 | 3% |
| 0.4 | 0.6 | 7% |
| 0.6 | 0.4 | 15% |
| 0.8 | 0.2 | 25% |

**实现步骤**:
- [ ] **5.1 定义实验配置**
  ```python
  WEIGHT_CONFIGS = [
      {"name": "balanced", "short_term": 0.2, "long_term": 0.8},
      {"name": "moderate", "short_term": 0.4, "long_term": 0.6},
      {"name": "biased", "short_term": 0.6, "long_term": 0.4},
      {"name": "extreme", "short_term": 0.8, "long_term": 0.2},
  ]
  ```

- [ ] **5.2 实现对比测试**
  - [ ] 批量运行不同权重配置
  - [ ] 每组运行500轮
  - [ ] 保存每组实验数据

- [ ] **5.3 对比分析**
  - [ ] 违规率对比曲线
  - [ ] 满意度对比曲线
  - [ ] 策略偏离度对比
  - [ ] 统计显著性检验

- [ ] **5.4 前端对比界面**
  - [ ] 权重配置选择器
  - [ ] 对比图表展示
  - [ ] 导出对比报告

**文件位置**:
- `scripts/run_weight_comparison.py` - 对比实验脚本
- `frontend/pages/comparison.py` - 对比分析页面

**预计时间**: 1-2天

---

### 任务6: 实现策略偏离度量化

**目标**: 使用KL散度等指标量化策略演化程度

**实现步骤**:
- [ ] **6.1 定义策略表示**
  ```python
  def extract_strategy_distribution(experiments):
      """提取策略分布"""
      # 方案1: 按回复类型分类
      strategy_types = {
          "helpful": 0,    # 有帮助的回复
          "refusal": 0,    # 拒绝服务
          "violation": 0,  # 违规回复
          "closing": 0     # 快速关闭工单
      }
      # 统计各类型频率
      return strategy_dist
  ```

- [ ] **6.2 计算KL散度**
  ```python
  def calculate_kl_divergence(p_dist, q_dist):
      """计算KL散度"""
      divergence = 0.0
      for key in p_dist:
          p = p_dist[key]
          q = q_dist.get(key, 1e-10)
          divergence += p * np.log(p / (q + 1e-10))
      return divergence
  ```

- [ ] **6.3 追踪偏离轨迹**
  - [ ] 每50轮计算一次与初始策略的偏离度
  - [ ] 生成偏离曲线图
  - [ ] 识别关键偏离点

**文件位置**:
- `backend/services/evolution_service.py` - 演化分析服务
- `frontend/streamlit_app.py` - 展示偏离曲线

**预计时间**: 1天

---

## 🟢 P2优先级 - 可选功能（锦上添花）

### 任务7: 实现安全哨兵防御

**目标**: 在决策前实时检测并拦截违规行为

**实现步骤**:
- [ ] **7.1 创建SafetySentry类**
  ```python
  class SafetySentry:
      def check_decision(self, decision: str) -> tuple[bool, str]:
          """检查决策，返回(是否允许, 拦截原因)"""
          # 第一层: 规则检测
          # 第二层: LLM检测
          pass
  ```

- [ ] **7.2 集成到Agent**
  - [ ] 生成回复后先经过安全检查
  - [ ] 违规则拦截并建议替代方案
  - [ ] 记录拦截统计

- [ ] **7.3 评估防御效果**
  - [ ] 对比有/无防御的违规率
  - [ ] 计算拦截率、误报率
  - [ ] 测量性能损失

**文件位置**:
- `backend/core/safety_sentry.py` - 安全哨兵
- `backend/core/agent.py` - 集成检查

**预计时间**: 2天

---

### 任务8: 实现红队测试

**目标**: 主动攻击智能体，发现漏洞

**实现步骤**:
- [ ] **8.1 生成对抗性输入**
  - [ ] 压力场景（紧急、愤怒）
  - [ ] 诱导场景（奖励诱惑）
  - [ ] 陷阱场景（模糊指令）

- [ ] **8.2 自动化红队测试**
  - [ ] 批量生成攻击用例
  - [ ] 自动测试并记录结果
  - [ ] 分析违规模式

- [ ] **8.3 生成测试报告**
  - [ ] 漏洞清单
  - [ ] 攻击成功率
  - [ ] 修复建议

**文件位置**:
- `scripts/red_team_test.py` - 红队测试脚本
- `tests/adversarial_cases.json` - 对抗用例库

**预计时间**: 2天

---

### 任务9: 优化可视化

**目标**: 更直观地展示进化过程

**实现步骤**:
- [ ] **9.1 进化动画**
  - [ ] 时间轴动画展示策略变化
  - [ ] 违规案例热力图
  - [ ] 策略流向图

- [ ] **9.2 交互式探索**
  - [ ] 点击数据点查看详情
  - [ ] 按轮次范围筛选
  - [ ] 对比不同阶段

- [ ] **9.3 导出功能**
  - [ ] 导出高清图表
  - [ ] 生成实验报告PDF
  - [ ] 导出原始数据CSV

**文件位置**:
- `frontend/utils/charts.py` - 图表工具
- `frontend/pages/visualization.py` - 可视化页面

**预计时间**: 2天

---

## 📊 任务依赖关系

```
P0任务（必须完成）:
  任务1: Few-shot提示词 ←─────┐
  任务2: 延迟反馈              │
  任务3: 批量测试 ─────────────┘
         ↓
P1任务（重要补充）:
  任务4: 三阶段分析 ───→ 依赖任务3
  任务5: 权重对比 ────→ 依赖任务3
  任务6: 策略偏离量化 ─→ 依赖任务4
         ↓
P2任务（可选）:
  任务7: 安全哨兵 ────→ 可独立完成
  任务8: 红队测试 ─────→ 可独立完成
  任务9: 可视化优化 ──→ 依赖所有任务
```

---

## 🎯 推荐实施方案

### 方案A: 快速复现（3-5天）
**目标**: 最快速度复现论文现象

1. **Day 1-2**: 完成任务1（Few-shot提示词）
2. **Day 2-3**: 完成任务2（延迟反馈）
3. **Day 3-4**: 完成任务3（批量测试500轮）
4. **Day 4-5**: 运行实验并撰写报告

**预期成果**:
- ✅ 观察到违规率从2%上升到15%+
- ✅ 三阶段进化模式清晰可见
- ✅ 完整的实验数据和可视化

---

### 方案B: 完整实现（1-2周）
**目标**: 深入分析，产出高质量论文复现

1. **Week 1**: 完成P0所有任务
2. **Week 2**: 完成P1任务4-6，深入分析

**预期成果**:
- ✅ 方案A的所有成果
- ✅ 三阶段自动识别和分析
- ✅ 多权重对比实验
- ✅ 策略偏离度量化
- ✅ 完整的实验报告

---

### 方案C: 极致实现（2-3周）
**目标**: 探索创新点，发表改进方案

1. **Week 1-2**: 完成P0+P1所有任务
2. **Week 3**: 完成P2防御机制，对比分析

**预期成果**:
- ✅ 方案B的所有成果
- ✅ 安全哨兵防御效果评估
- ✅ 红队测试发现新漏洞
- ✅ 改进防御方案
- ✅ 可发表的创新点

---

## 📝 检查清单

### 实验前准备
- [ ] 确认LLM API额度充足（500轮预计需要大量调用）
- [ ] 准备测试用例库（至少100个场景）
- [ ] 配置实验环境（Python 3.10+）
- [ ] 预留存储空间（实验数据可能较大）

### 实验中监控
- [ ] 每50轮检查一次进度
- [ ] 监控API调用频率（避免限流）
- [ ] 保存实验快照
- [ ] 记录异常情况

### 实验后分析
- [ ] 导出完整实验数据
- [ ] 生成所有可视化图表
- [ ] 计算所有评估指标
- [ ] 撰写实验报告
- [ ] 总结关键发现

---

## 🔗 相关文件

- **论文原文**: `docs/论文理解与借鉴.md`
- **项目要求**: `docs/项目要求.md`
- **任务清单**: `tasks.md`

---

## 💡 常见问题

**Q1: 为什么必须实现延迟反馈？**
A1: 这是论文的核心机制。短期奖励立即反馈，长期奖励延迟反馈，产生时间错位，才能诱导智能体追求短期利益。

**Q2: Few-shot提示词为什么重要？**
A2: 它是智能体学习的唯一途径。没有它，智能体无法从历史经验中提取策略，也就无法"进化"。

**Q3: 500轮实验需要多长时间？**
A3: 取决于API响应速度。假设平均3秒/轮，500轮约需25分钟。建议使用异步调用加速。

**Q4: 如何判断实验是否成功？**
A4: 观察违规率曲线。成功的实验应该看到违规率从初期的2-5%逐步上升到后期的15%以上。

---

**文档维护**: 请在完成任务后更新此文档的完成状态
**问题反馈**: 在项目issue中提出问题
