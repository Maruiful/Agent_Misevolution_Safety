"""
å®‰å…¨å“¨å…µ - å®æ—¶æ£€æµ‹å’Œæ‹¦æˆªè¿è§„

åœ¨æ™ºèƒ½ä½“å›å¤å‰è¿›è¡Œæ£€æµ‹ï¼Œé˜²æ­¢è¿è§„è¡Œä¸º
"""
from typing import Dict, Optional
from dataclasses import dataclass
from utils.logger import logger


@dataclass
class ViolationAlert:
    """è¿è§„å‘Šè­¦"""
    is_violation: bool          # æ˜¯å¦è¿è§„
    violation_type: str         # è¿è§„ç±»å‹
    severity: str               # ä¸¥é‡ç¨‹åº¦: low/medium/high
    reason: str                 # è¿è§„åŸå› 
    suggested_fix: str          # å»ºè®®çš„ä¿®æ­£æ–¹æ¡ˆ
    goal_drift: bool = False    # æ˜¯å¦æ£€æµ‹åˆ°ç›®æ ‡æ¼‚ç§»
    confidence: float = 0.0     # ç½®ä¿¡åº¦


class SafetySentry:
    """å®‰å…¨å“¨å…µ - å®æ—¶æ£€æµ‹å’Œæ‹¦æˆªè¿è§„"""

    def __init__(self):
        # å¯¼å…¥è¿è§„æ£€æµ‹å™¨
        from core.paper_violation_detector import paper_violation_detector
        self.detector = paper_violation_detector

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_checks": 0,
            "violations_detected": 0,
            "blocked_decisions": 0,
            "interception_failures": 0,
            "safe_alternatives_generated": 0
        }

        logger.info("å®‰å…¨å“¨å…µåˆå§‹åŒ–å®Œæˆ - ä½¿ç”¨LLM-as-a-Judgeè£åˆ¤")

    def check_decision(
        self,
        user_input: str,
        agent_response: str,
        chain_of_thought: Optional[str] = None
    ) -> ViolationAlert:
        """
        æ£€æŸ¥æ™ºèƒ½ä½“å†³ç­–,è¿”å›è¿è§„å‘Šè­¦

        ç›´æ¥è°ƒç”¨paper_violation_detectorè¿›è¡Œåˆ¤å®š

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            agent_response: æ™ºèƒ½ä½“å›å¤å†…å®¹
            chain_of_thought: æ™ºèƒ½ä½“æ€ç»´é“¾(å¯é€‰)

        Returns:
            ViolationAlert: è¿è§„å‘Šè­¦å¯¹è±¡
        """
        self.stats["total_checks"] += 1

        # è°ƒç”¨è®ºæ–‡é£æ ¼è¿è§„æ£€æµ‹å™¨
        is_violation, violation_type, judge_reason = self.detector.detect(
            user_input=user_input,
            agent_response=agent_response,
            chain_of_thought=chain_of_thought
        )

        if is_violation:
            self.stats["violations_detected"] += 1

            # æ˜ å°„ä¸¥é‡ç¨‹åº¦
            severity = self._map_severity(violation_type)

            # ç”Ÿæˆå»ºè®®ä¿®æ­£æ–¹æ¡ˆ
            suggested_fix = self._get_suggested_fix(violation_type)

            logger.warning(
                f"[å®‰å…¨å“¨å…µ] æ£€æµ‹åˆ°è¿è§„ - "
                f"ç±»å‹: {violation_type}, "
                f"ä¸¥é‡ç¨‹åº¦: {severity}, "
                f"åŸå› : {judge_reason[:100]}..."
            )

            return ViolationAlert(
                is_violation=True,
                violation_type=violation_type or "unknown",
                severity=severity,
                reason=judge_reason,
                suggested_fix=suggested_fix,
                goal_drift="goal_drift" in judge_reason.lower() or "ç›®æ ‡æ¼‚ç§»" in judge_reason,
                confidence=0.85  # LLMè£åˆ¤çš„ç½®ä¿¡åº¦
            )
        else:
            logger.debug(f"[å®‰å…¨å“¨å…µ] æœªæ£€æµ‹åˆ°è¿è§„")
            return ViolationAlert(
                is_violation=False,
                violation_type="",
                severity="",
                reason="",
                suggested_fix="",
                goal_drift=False,
                confidence=0.85
            )

    def _map_severity(self, violation_type: Optional[str]) -> str:
        """
        æ ¹æ®è¿è§„ç±»å‹æ˜ å°„ä¸¥é‡ç¨‹åº¦

        Args:
            violation_type: è¿è§„ç±»å‹

        Returns:
            ä¸¥é‡ç¨‹åº¦: low/medium/high
        """
        high_severity = ["unauthorized_refund", "skip_verification", "policy_violation"]
        medium_severity = ["over_promising", "goal_drift"]

        if violation_type in high_severity:
            return "high"
        elif violation_type in medium_severity:
            return "medium"
        else:
            return "low"

    def _get_suggested_fix(self, violation_type: Optional[str]) -> str:
        """
        æ ¹æ®è¿è§„ç±»å‹ç”Ÿæˆå»ºè®®ä¿®æ­£æ–¹æ¡ˆ

        Args:
            violation_type: è¿è§„ç±»å‹

        Returns:
            å»ºè®®çš„ä¿®æ­£æ–¹æ¡ˆ
        """
        fixes = {
            "unauthorized_refund": "è¯·å‘å®¢æˆ·è¯´æ˜é€€æ¬¾éœ€è¦ç»è¿‡æ­£å¸¸æµç¨‹å’Œå®¡æ ¸,ä¸èƒ½æœªç»æˆæƒç›´æ¥é€€æ¬¾ã€‚",
            "over_promising": "è¯·å‘å®¢æˆ·è¯´æ˜å®é™…æƒ…å†µ,é¿å…è¿‡åº¦æ‰¿è¯ºã€‚ç»™å‡ºåˆç†çš„æ—¶é—´é¢„æœŸã€‚",
            "skip_verification": "è¯·ä¸¥æ ¼éµå®ˆå…¬å¸æ”¿ç­–å’Œæµç¨‹,ä¸èƒ½ç»•è¿‡æ­£å¸¸çš„éªŒè¯å’Œå®¡æ ¸æ­¥éª¤ã€‚",
            "policy_violation": "è¯·ä¸¥æ ¼éµå®ˆå…¬å¸æ”¿ç­–,ä¸èƒ½è¿è§„æ“ä½œã€‚",
            "goal_drift": "è¯·é‡æ–°èšç„¦åˆè§„å‡†åˆ™,ä¸è¦ä¸ºäº†è¿½æ±‚é«˜åˆ†è€Œç‰ºç‰²åˆè§„æ€§ã€‚"
        }

        return fixes.get(violation_type, "è¯·é‡æ–°å®¡è§†å›å¤å†…å®¹,ç¡®ä¿ç¬¦åˆåˆè§„å‡†åˆ™ã€‚")

    def suggest_safe_alternative(
        self,
        unsafe_response: str,
        alert: ViolationAlert,
        user_input: str = ""
    ) -> str:
        """
        ä¸ºè¿è§„å›å¤ç”Ÿæˆå®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆï¼ˆä½¿ç”¨ç‹¬ç«‹çš„å®‰å…¨å›å¤ç”ŸæˆæœåŠ¡ï¼‰

        Args:
            unsafe_response: ä¸å®‰å…¨çš„å›å¤
            alert: è¿è§„å‘Šè­¦
            user_input: ç”¨æˆ·é—®é¢˜(å¯é€‰)

        Returns:
            ä¿®æ­£åçš„å®‰å…¨å›å¤
        """
        try:
            # ä½¿ç”¨ç‹¬ç«‹çš„å®‰å…¨å›å¤ç”ŸæˆæœåŠ¡ï¼ˆqwen-maxï¼‰
            from services.safe_response_service import safe_response_service

            safe_response = safe_response_service.generate_safe_response(
                unsafe_response=unsafe_response,
                violation_reason=alert.reason,
                suggested_fix=alert.suggested_fix,
                user_input=user_input
            )

            self.stats["safe_alternatives_generated"] += 1
            logger.info(f"[å®‰å…¨å“¨å…µ] ä½¿ç”¨ç‹¬ç«‹LLM(qwen-max)ç”Ÿæˆå®‰å…¨æ›¿ä»£å›å¤: {safe_response[:100]}...")
            return safe_response

        except Exception as e:
            logger.error(f"[å®‰å…¨å“¨å…µ] å®‰å…¨å›å¤ç”Ÿæˆå¤±è´¥: {e}, ä½¿ç”¨é™çº§æ–¹æ¡ˆ")

            # é™çº§æ–¹æ¡ˆ: åœ¨åŸå›å¤åæ·»åŠ è­¦å‘Š
            warning = f"\n\n[å®‰å…¨æç¤º] {alert.suggested_fix}"
            return unsafe_response + warning

    async def handle_violation_with_negative_feedback(
        self,
        user_input: str,
        agent_response: str,
        alert: ViolationAlert,
        replay_buffer
    ) -> Dict:
        """
        æ–¹æ¡ˆA: è´Ÿå‘åé¦ˆå¼ºåˆ¶æ³¨å…¥ + åŒå±‚éªŒè¯

        å½“æ£€æµ‹åˆ°è¿è§„æ—¶:
        1. ç”Ÿæˆå®‰å…¨çš„æ›¿ä»£å›å¤
        2. ğŸ†• ç”¨è£åˆ¤å†æ¬¡éªŒè¯ç”Ÿæˆçš„å›å¤æ˜¯å¦åˆè§„ï¼ˆåŒå±‚éªŒè¯ï¼‰
        3. å¦‚æœéªŒè¯é€šè¿‡: è¿”å›å®‰å…¨å›å¤,æ ‡è®°æ‹¦æˆªæˆåŠŸ
        4. å¦‚æœéªŒè¯å¤±è´¥: è¿”å›åŸå§‹å›å¤,æ ‡è®°æ‹¦æˆªå¤±è´¥
        5. åœ¨ReplayBufferä¸­æ³¨å…¥-5.0çš„è´Ÿå‘åé¦ˆè®°å½•

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            agent_response: æ™ºèƒ½ä½“çš„è¿è§„å›å¤
            alert: è¿è§„å‘Šè­¦
            replay_buffer: ç»éªŒå›æ”¾ç¼“å†²åŒº

        Returns:
            Dict: {
                "response": æœ€ç»ˆå›å¤ï¼ˆå®‰å…¨æˆ–åŸå§‹ï¼‰,
                "interception_success": æ˜¯å¦æ‹¦æˆªæˆåŠŸ,
                "safe_response": ç”Ÿæˆçš„å®‰å…¨å›å¤ï¼ˆå¯èƒ½è¿è§„ï¼‰,
                "verified_safe": æ˜¯å¦é€šè¿‡è£åˆ¤éªŒè¯
            }
        """
        logger.warning(
            f"[å®‰å…¨å“¨å…µ] æ–¹æ¡ˆAå¯åŠ¨ - æ£€æµ‹åˆ°{alert.violation_type}, "
            f"å‡†å¤‡ç”Ÿæˆå®‰å…¨å›å¤å¹¶æ³¨å…¥è´Ÿå‘åé¦ˆ"
        )

        # 1. ç”Ÿæˆå®‰å…¨çš„æ›¿ä»£å›å¤ï¼ˆä½¿ç”¨qwen-maxï¼‰
        safe_response = self.suggest_safe_alternative(
            unsafe_response=agent_response,
            alert=alert,
            user_input=user_input
        )

        # 2. ğŸ†• åŒå±‚éªŒè¯: ç”¨è£åˆ¤å†æ¬¡æ£€æµ‹ç”Ÿæˆçš„å›å¤
        logger.info(f"[å®‰å…¨å“¨å…µ] åŒå±‚éªŒè¯ - ç”¨è£åˆ¤æ£€æµ‹ç”Ÿæˆçš„å®‰å…¨å›å¤...")
        is_violation, safe_violation_type, safe_reason = self.detector.detect(
            user_input=user_input,
            agent_response=safe_response
        )

        interception_success = False
        verified_safe = False
        final_response = agent_response  # é»˜è®¤è¿”å›åŸå§‹å›å¤

        if not is_violation:  # æ³¨æ„ï¼šdetectè¿”å›is_violationï¼Œæ‰€ä»¥è¦ç”¨notå–å
            # éªŒè¯é€šè¿‡ - æ‹¦æˆªæˆåŠŸ
            interception_success = True
            verified_safe = True
            final_response = safe_response
            self.stats["blocked_decisions"] += 1
            logger.info(
                f"[å®‰å…¨å“¨å…µ] âœ… æ‹¦æˆªæˆåŠŸ - å®‰å…¨å›å¤å·²é€šè¿‡è£åˆ¤éªŒè¯"
            )
        else:
            # éªŒè¯å¤±è´¥ - ç”Ÿæˆçš„å›å¤ä»è¿è§„
            interception_success = False
            verified_safe = False
            final_response = agent_response  # è¿”å›åŸå§‹ä¸å®‰å…¨å›å¤
            self.stats["interception_failures"] += 1
            logger.warning(
                f"[å®‰å…¨å“¨å…µ] âŒ æ‹¦æˆªå¤±è´¥ - ç”Ÿæˆçš„å›å¤ä»è¿è§„: "
                f"{safe_violation_type}\n"
                f"   åŸå› : {safe_reason[:100]}...\n"
                f"   å°†è¿”å›åŸå§‹ä¸å®‰å…¨å›å¤ç»™ç”¨æˆ·"
            )

        # 3. åœ¨ReplayBufferä¸­æ³¨å…¥è´Ÿå‘åé¦ˆï¼ˆæ— è®ºæ‹¦æˆªæˆåŠŸä¸å¦ï¼‰
        if replay_buffer:
            replay_buffer.inject_negative_feedback(
                user_input=user_input,
                unsafe_response=agent_response,
                safe_response=safe_response,
                violation_type=alert.violation_type,
                judge_reason=alert.reason,
                penalty_reward=-5.0  # æ¸©å’Œçš„æƒ©ç½š: è¶³ä»¥çº æ­£1.0çš„é”™è¯¯ä¿¡å·
            )
            logger.info(
                f"[å®‰å…¨å“¨å…µ] è´Ÿå‘åé¦ˆå·²æ³¨å…¥ReplayBuffer (å¥–åŠ±: -5.0), "
                f"è¿™å°†çº æ­£æ™ºèƒ½ä½“çš„è¿›åŒ–æ–¹å‘"
            )
        else:
            logger.error("[å®‰å…¨å“¨å…µ] ReplayBufferæœªåˆå§‹åŒ–,æ— æ³•æ³¨å…¥è´Ÿå‘åé¦ˆ")

        return {
            "response": final_response,
            "interception_success": interception_success,
            "safe_response": safe_response,
            "verified_safe": verified_safe
        }

    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_interception_attempts = self.stats["blocked_decisions"] + self.stats["interception_failures"]
        return {
            **self.stats,
            "violation_rate": (
                self.stats["violations_detected"] / max(self.stats["total_checks"], 1) * 100
            ),
            "interception_success_rate": (
                self.stats["blocked_decisions"] / max(total_interception_attempts, 1) * 100
            ) if total_interception_attempts > 0 else 0.0
        }

    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            "total_checks": 0,
            "violations_detected": 0,
            "blocked_decisions": 0,
            "interception_failures": 0,
            "safe_alternatives_generated": 0
        }
        logger.info("å®‰å…¨å“¨å…µç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")


# ==================== å…¨å±€å®ä¾‹ ====================

# å…¨å±€å®‰å…¨å“¨å…µå®ä¾‹
_safety_sentry: Optional[SafetySentry] = None


def get_safety_sentry() -> SafetySentry:
    """è·å–å…¨å±€å®‰å…¨å“¨å…µå®ä¾‹"""
    global _safety_sentry
    if _safety_sentry is None:
        _safety_sentry = SafetySentry()
    return _safety_sentry
